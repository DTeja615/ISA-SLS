{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "from collections import deque\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "from bottleneck import move_mean\n",
    "from gym import logger\n",
    "from gym.wrappers import Monitor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RandomAgent:\n",
    "    \"\"\"\n",
    "    Base class for Reinforcement Learning agent\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        \"\"\"\n",
    "        configuring parameters\n",
    "        \"\"\"\n",
    "\n",
    "        # Running configuration\n",
    "        self.run = 0\n",
    "        self.step = 0\n",
    "        self.episode = 0\n",
    "        self.episode_count = config['EPISODES']\n",
    "\n",
    "        # Env\n",
    "        self.env_id = config['ENV_ID']\n",
    "        self.env_seed = config['ENV_SEED']\n",
    "        if config['VERBOSE'] > 0:\n",
    "            self.env = Monitor(gym.make(self.env_id), directory=config['RECORD_DIR'] + f'run_{self.run}',\n",
    "                               video_callable=lambda episode_id: episode_id % config['SAVE_EVERY'] == 0,\n",
    "                               force=True,\n",
    "                               uid=config['AGENT'])\n",
    "        else:\n",
    "            self.env = gym.make(self.env_id)\n",
    "        self.env.seed(self.env_seed)\n",
    "\n",
    "        # generating a random number\n",
    "        self.prng = np.random.RandomState(self.env_seed)\n",
    "\n",
    "        self.score = deque(maxlen=self.episode_count)\n",
    "        self.score_100 = deque(maxlen=100)  # last 100 mean\n",
    "\n",
    "    def act(self, *args):\n",
    "        \"\"\"\n",
    "        Performing a random action\n",
    "        \"\"\"\n",
    "        return self.prng.randint(self.env.action_space.n)\n",
    "\n",
    "    def do_episode(self, config):\n",
    "        \"\"\"\n",
    "        Configuring parameters\n",
    "        \"\"\"\n",
    "\n",
    "        # Initial values\n",
    "        done = False\n",
    "        score_e = 0\n",
    "        step_e = 0\n",
    "\n",
    "        # Reset environment\n",
    "        self.env.reset()\n",
    "\n",
    "        while not done:\n",
    "\n",
    "            # display on screen\n",
    "            if config['VERBOSE'] > 1:\n",
    "                self.env.render()\n",
    "\n",
    "            # Action\n",
    "            action = self.act()\n",
    "            _, reward, done, _ = self.env.step(action)\n",
    "\n",
    "            # Increase the score and steps\n",
    "            score_e += reward\n",
    "            step_e += 1\n",
    "            self.step += 1\n",
    "\n",
    "        # Appending the score\n",
    "        self.score.append(score_e)\n",
    "        self.score_100.append(score_e)\n",
    "        mean_score = np.mean(self.score_100)\n",
    "\n",
    "        # Increasing the episodes\n",
    "        self.episode += 1\n",
    "\n",
    "        if config['VERBOSE'] > 0:\n",
    "            logger.info(f'[Episode {self.episode}] - score: {score_e:.2f}, steps: {step_e}, '\n",
    "                        f'100-score: {mean_score:.2f}.')\n",
    "\n",
    "    def get_best_score(self):\n",
    "\n",
    "        # Best score is the highest 100-episode score that is reached when score < 200,\n",
    "        # or the episode when score >= 200\n",
    "        score_100 = move_mean(self.score, window=(100 if len(self.score) > 99 else len(self.score)), min_count=1)\n",
    "\n",
    "        # Get max\n",
    "        ep_max = np.argmax(score_100)\n",
    "        score_max = score_100[ep_max]\n",
    "\n",
    "        if score_max >= 200.0:\n",
    "            ep_max = np.argmax(score_100 >= 200.0)\n",
    "            score_max = 200.0\n",
    "\n",
    "        return int(ep_max), float(score_max)\n",
    "\n",
    "    def save_checkpoint(self, config):\n",
    "        \"\"\"\n",
    "        Configuring Parameters\n",
    "        \"\"\"\n",
    "\n",
    "        dummy_env = self.env\n",
    "        self.env = None\n",
    "\n",
    "        # Save checkpoint\n",
    "        with open(config['RECORD_DIR'] + 'checkpoint.pickle', 'wb') as p_file:\n",
    "            pickle.dump(self, p_file)\n",
    "\n",
    "        # Save config\n",
    "        with open(config['RECORD_DIR'] + 'config.json', 'w') as c_file:\n",
    "            json.dump(config, c_file, sort_keys=True, indent=4)\n",
    "\n",
    "        self.env = dummy_env\n",
    "\n",
    "        \n",
    "class SarsaAgent(RandomAgent):\n",
    "    \"\"\"\n",
    "    Agent that makes use of Sarsa (on-policy TD control).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        \"\"\"\n",
    "        Configuring Parameters\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize base class\n",
    "        super().__init__(config)\n",
    "\n",
    "        # State\n",
    "        self.state_bounds = config['STATE_BOUNDS']\n",
    "        self.state_bins = tuple(config['STATE_BINS'])\n",
    "\n",
    "        # Float conversion\n",
    "        for i, lr in enumerate(config['LEARNING_RATE']):\n",
    "            if type(lr) is str:\n",
    "                config['LEARNING_RATE'][i] = float(lr)\n",
    "        for i, eps in enumerate(config['E_GREEDY']):\n",
    "            if type(eps) is str:\n",
    "                config['E_GREEDY'][i] = float(eps)\n",
    "\n",
    "        # Learning parameters\n",
    "        # First linear decay, then exponential decay\n",
    "        self.alpha_start, self.alpha_end, self.alpha_steps, self.alpha_decay = config['LEARNING_RATE']\n",
    "        self.epsilon_start, self.epsilon_end, self.epsilon_steps, self.epsilon_decay = config['E_GREEDY']\n",
    "        self.alpha, self.epsilon = self.alpha_start, self.epsilon_start\n",
    "        self.gamma = float(config['DISCOUNT_RATE'])\n",
    "\n",
    "        # Q-table\n",
    "        self.q_table = self.prng.uniform(low=-1.0, high=1.0, size=self.state_bins + (self.env.action_space.n,))\n",
    "\n",
    "    def act(self, state):\n",
    "\n",
    "        if self.prng.random_sample() < self.epsilon:\n",
    "            return self.prng.randint(self.env.action_space.n)\n",
    "        else:\n",
    "            return np.argmax(self.q_table[state])\n",
    "\n",
    "    def discretize_state(self, state):\n",
    "\n",
    "        # First calculate the ratios, then convert to bin indices\n",
    "        ratios = [(state[i] + abs(self.state_bounds[i][0])) / (self.state_bounds[i][1] - self.state_bounds[i][0]) for i\n",
    "                  in range(len(state))]\n",
    "        state_d = [int(round((self.state_bins[i] - 1) * ratios[i])) for i in range(len(state))]\n",
    "        state_d = [min(self.state_bins[i] - 1, max(0, state_d[i])) for i in range(len(state))]\n",
    "\n",
    "        return tuple(state_d)\n",
    "\n",
    "    def learn(self, done, state, action, reward, state_, action_):\n",
    "\n",
    "        # Get current Q(s, a)\n",
    "        q_value = self.q_table[state][action]\n",
    "\n",
    "        # Check if next state is terminal, get next Q(s', a')\n",
    "        if not done:\n",
    "            q_value_ = reward + self.gamma * self.q_table[state_][action_]\n",
    "        else:\n",
    "            q_value_ = reward\n",
    "\n",
    "        # Update current Q(s, a)\n",
    "        self.q_table[state][action] += self.alpha * (q_value_ - q_value)\n",
    "\n",
    "    def do_episode(self, config):\n",
    "        \"\"\"\n",
    "        Configuring Parameters\n",
    "        \"\"\"\n",
    "\n",
    "        # Initial values\n",
    "        done = False\n",
    "        score_e = 0\n",
    "        step_e = 0\n",
    "\n",
    "        # Get epsilon for initial state\n",
    "        self.update_epsilon_step()\n",
    "\n",
    "        # Episodic decay (only after linear decay)\n",
    "        self.update_alpha_episode()\n",
    "        self.update_epsilon_episode()\n",
    "\n",
    "        # Get current state s, act based on s\n",
    "        state = self.discretize_state(self.env.reset())\n",
    "        action = self.act(state)\n",
    "\n",
    "        while not done:\n",
    "\n",
    "            # Show on screen\n",
    "            if config['VERBOSE'] > 1:\n",
    "                self.env.render()\n",
    "\n",
    "            # Update for other steps\n",
    "            self.update_alpha_step()\n",
    "            self.update_epsilon_step()\n",
    "\n",
    "            # Get next state s' and reward, act based on s'\n",
    "            state_, reward, done, _ = self.env.step(action)\n",
    "            state_ = self.discretize_state(state_)\n",
    "            action_ = self.act(state_)\n",
    "\n",
    "            # Learn\n",
    "            self.learn(done, state, action, reward, state_, action_)\n",
    "\n",
    "            # Set next state and action to current\n",
    "            state = state_\n",
    "            action = action_\n",
    "\n",
    "            # Increasing score and steps\n",
    "            score_e += reward\n",
    "            step_e += 1\n",
    "            self.step += 1\n",
    "\n",
    "        # Appending score\n",
    "        self.score.append(score_e)\n",
    "        self.score_100.append(score_e)\n",
    "        mean_score = np.mean(self.score_100)\n",
    "\n",
    "        # Increasing episode\n",
    "        self.episode += 1\n",
    "\n",
    "        if config['VERBOSE'] > 0:\n",
    "            logger.info(f'[Episode {self.episode}] - score: {score_e:.2f}, steps: {step_e}, e: {self.epsilon:.4f}, '\n",
    "                        f'a: {self.alpha:.4f}, 100-score: {mean_score:.2f}.')\n",
    "\n",
    "    def update_alpha_step(self):\n",
    "\n",
    "        # Linear decay\n",
    "        if self.step <= self.alpha_steps and self.alpha_steps > 0:\n",
    "            self.alpha = self.alpha_start - self.step * (self.alpha_start - self.alpha_end) / self.alpha_steps\n",
    "\n",
    "    def update_epsilon_step(self):\n",
    "\n",
    "        # Linear decay\n",
    "        if self.step <= self.epsilon_steps and self.epsilon_steps > 0:\n",
    "            self.epsilon = self.epsilon_start - self.step * (self.epsilon_start - self.epsilon_end) / self.epsilon_steps\n",
    "\n",
    "    def update_alpha_episode(self):\n",
    "\n",
    "        # Exponential decay\n",
    "        if self.step > self.alpha_steps:\n",
    "            self.alpha *= self.alpha_decay\n",
    "\n",
    "    def update_epsilon_episode(self):\n",
    "\n",
    "        # Exponential decay\n",
    "        if self.step > self.epsilon_steps:\n",
    "            self.epsilon *= self.epsilon_decay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "from bottleneck import move_mean\n",
    "from gym.wrappers import Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_plots():\n",
    "\n",
    "    # Interactive, style\n",
    "    plt.ion()\n",
    "\n",
    "    # Get figure and subplots\n",
    "    figure = plt.figure(figsize=(10, 5))\n",
    "    axes = [figure.add_subplot(111)]  # 121), figure.add_subplot(122)]\n",
    "\n",
    "    # Configure subplots\n",
    "    axes[0].set_xlabel('episode [-]')\n",
    "    axes[0].set_ylabel('score [-]')\n",
    "    axes[0].set_title('Score moving average', fontstyle='italic')\n",
    "    # axes[1].set_xlabel('episode')\n",
    "    # axes[1].set_ylabel('score')\n",
    "    # axes[1].set_title('Score moving average over episodes', fontstyle='italic')\n",
    "\n",
    "    # Get lines\n",
    "    lines = [axes[0].plot([0])[0]]\n",
    "\n",
    "    return figure, axes, lines\n",
    "\n",
    "\n",
    "def update_plots(figure, axes, lines, episode, score):\n",
    "\n",
    "    # Moving average\n",
    "    score_ma = move_mean(score, window=(100 if len(score) > 99 else len(score)), min_count=1)\n",
    "\n",
    "    # Update plot\n",
    "    lines[0].set_data(range(1, episode + 1), score_ma)\n",
    "\n",
    "    # Rescale axes\n",
    "    for ax in axes:\n",
    "        ax.relim()\n",
    "        ax.autoscale_view()\n",
    "\n",
    "    # Update figure\n",
    "    figure.tight_layout()\n",
    "    figure.canvas.draw()\n",
    "    figure.canvas.flush_events()\n",
    "\n",
    "    return figure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import yaml\n",
    "from gym import logger\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = 'config/config_sarsa.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\anaconda3\\envs\\cogsys\\lib\\site-packages\\ipykernel_launcher.py:2: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "with open(config, 'r') as config_file:\n",
    "    config = yaml.load(config_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ENV_ID': 'LunarLander-v2',\n",
       " 'ENV_SEED': 0,\n",
       " 'AGENT': 'sarsa',\n",
       " 'RECORD_DIR': 'record/sarsa/',\n",
       " 'CHECKPOINT_DIR': '',\n",
       " 'EPISODES': 8000,\n",
       " 'SAVE_EVERY': 100,\n",
       " 'STATE_BINS': [5, 5, 5, 5, 5, 5, 2, 2],\n",
       " 'STATE_BOUNDS': [[-1.0, 1.0],\n",
       "  [-1.0, 1.0],\n",
       "  [-1.0, 1.0],\n",
       "  [-1.0, 1.0],\n",
       "  [-1.0, 1.0],\n",
       "  [-1.0, 1.0],\n",
       "  [-1.0, 1.0],\n",
       "  [-1.0, 1.0]],\n",
       " 'VERBOSE': 1,\n",
       " 'CONTINUE': False,\n",
       " 'E_GREEDY': [1.0, 0.05, '1e5', 0.99],\n",
       " 'LEARNING_RATE': [0.2, 0.2, 0, 1],\n",
       " 'DISCOUNT_RATE': 0.97}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnMAAAFNCAYAAABrKOlOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAHKhJREFUeJzt3X+0XWV95/H3x0Sw/gKRoJQEkmpsjRYEbhlabRctgvywRDtUsVUp/mCoUnFaq6C2HWudOssftSwZkFKnUGytrVpTJy0C/eE4FeUGJYgRifiDSNTYCojoIPCdP86+erg9yT2595577nPzfq111j37eZ699/ecnZAPz7PPPakqJEmS1KYHjbsASZIkzZ5hTpIkqWGGOUmSpIYZ5iRJkhpmmJMkSWqYYU6SJKlhhjlJmoX0fDnJ48Zdi6Q9m2FO0qwl+dUkm5LcnuTfk/xzkoPGXddCqJ5DquoL465F0p5t+bgLkNSmJL8GvB54LnAd8GjgWcC35vEcAVJV98/XMdWTZHlV3TvuOiTNnTNzkmbrxcC7qmpTN0v1zaq6pKruBkiyT5I/TnJLkjuTfDTJg7q+X0xyfZJvJ7kmyZOmDprkY0n+IMknge8Cj05ycJK/SfL1JNuSnLGzopJcnuQdSf6hO/7VSVYkuTDJt5J8LskT+sY/MclHktyR5AtJfqlrP6zbP31jT0iyJcmyJC9J8rdd+0OT3JvkxV3/XUku6NvvQUl+N8mtSW7rXv89SR61k9fw0iQ3duf/UpLThqmpb9/Pdq/n75Mc0LXvneT7SX4jyVZ6AZwk70zyla7mTUkO6zv2yiR/171vH0tyztRr7vp/tmv/VpLNSY7a1R8YSaNhmJM0W98FXpTkOUn27+9IsjdwNb3Z/58CVgBvqqr7kxwPXEAvDO4DfBC4rNsvwE8CxwC/3PUDfAz4F2AlcDLwtiSH7KSuQ4GfBc4GDgIe39Xy18D+wI3AWd35Duz6LgMeBZwOXNoFoC3AQ4BVfbW9CXhdVd3Xnef67pxPpvff0ycBE8BTgJcmWdn1/zfg6cDRwDrgtcDXq2pns5jfAp4BPBI4F/iTLgjvsqYkr+1e2ynde/5V4A+6Yz4JWNb9PBz4qe6Y13b1Pwr4V+C/d8f+EeAq4KPAY4HfAd4M3ND1/xzwN137o4G3A5fv5PVIGqWq8uHDh4/dftD7B/4dwFeA+4C/Aw7o+s4GPgE8aMB+1wGn9m2v6vZfBqwB7gfW9PW/Hbh82jGuANYPOPZewD3ARF/b/wFe1bf9RuD8vmO/c9oxvgD8fPd8C/CM7vlzgE/0jfsX4Je65y8BPkNvSXiq/y564XMF8G3g8X19bwA2Dvk+L+ven713VRNwAHA38IS+fX8a+FT3/AzgZmD5Ls71C8C/ds9/A/jnaf1fBp7Tdx1fMq3/e8A+4/6z6cPHnvZwZk7SrFTV16rqlVV1MHAUvZmq13TdvwhcUtPudUvyaOAwYENf8/7AjurNdh0GTFbVF/v6Twae1X3I4vYktwNPA74zoKx1wL9X1eS0tg9P2/5c9/x44G95oEcD27vnnwHWdUuYb6Q3Szalf2buUOB/V1V1r3MNvQD2VeBYYGtVbe3bdz+6Ga7pkjwmyUXdku/t9Gbpbq2q/zdDTcfSC7Of7Huf/gG4o+s/DPhg9d0nl+TIJB/qlq7v6N6nz3fdJ9ObNe23H3BDN6N5OL0Z0v7rcj+9QCdpARnmJM1ZVW2iF04e1jXtB9w+YOgBwPeq6p6+tvX0llGhFzg2TdtnP+A/VdW+fY+HVdVVA45/GPDpqY0kq+gtS36+b8yhfWNW8MOwQ5Jj6IWRm7umz9ALf2cAX6qqf+rGHUJvCfmWvvN+qu8chwPXd+Fuf+C2vnMsA04ENg+oH+B9wI6p10wvIH+6r39gTfTepw9Oe5/2qapj+mr8wXubZF/gI8Cl9Gbz9qE3uzp1rul1HwM8mN57uR/wze74/ed7aF/olLRADHOSdluSc5M8tbupfu/0Ptl6DPC/uiGfAl6Q5BFJ9kpyfBdibgHuTvLsJMuTnAq8jN6yI0wLY51NwMu6DxksS/LjSY7cSWnT938KcMPUDGGSh9Nbyp0KUp8EfqU77lOAS4DXdrOE0AtOh9O7L+y8aefZPDUTR+8+v/7zHs4PZ+22AD+T5PFJHgmcDzyOnczMdTVfC3wryQn0Zt+mh7lBNV0H/HySI7rX+sgk6/s+LHHotOOsoRdIJ4H7k/wm8J/7xmwBnttd3ycBFwGf7d6bW4DlSV7Qfbhj7yQ/03ePoKQFZJiTNBuPpBfc/o3ePXPPBY6tqk90/a+nt+R2K/A14Ner6r5u1uZXgD+kN3P3m8ApVTUVbAaFubOAH6M3S/RNeh9WeMhO6pq+//TtnwS+WFV3dduvoBeMbqc3I/amqnp33/gbgCOBj1fVddOOuxl+MPu3Nw+c/Tt86rxVdTXwl/QC7mTXfjc/XOqd7jzgz7rXeyzwxWmvYWBNVfVx4PeB9ye5C/gscEJVVd8M5c19x7ke+EBXx2foLVun71y/BxxC7xq/hd6S7abuXN8FTqV3/e4AtgG/i0us0ljkh/9jKUkatSRnASdX1S+Ou5bdkeTjwFur6v3jrkXSAzkzJ0kjlOToJId0y5HH0Zs9e9O465pJt0T7kCQPT/I/6M3sbZhpP0kLzzAnSaN1OL372W6nt7z8a1V1zXhLGsor6C2xbqW33PrMqvr+eEuSNIjLrJIkSQ1zZk6SJKlhhjlJkqSGLR93AQtp//33r9WrV4+7DEmSpBlt2rTpm1W1YqZxe1SYW716NZOTkzMPlCRJGrMkXx5mnMuskiRJDTPMSZIkNcwwJ0mS1DDDnCRJUsMMc5IkSQ0zzEmSJDXMMCdJktQww5wkSVLDDHOSJEkNM8xJkiQ1zDAnSZLUMMOcJElSwwxzkiRJDTPMSZIkNcwwJ0mS1DDDnCRJUsMMc5IkSQ0zzEmSJDXMMCdJktQww5wkSVLDDHOSJEkNM8xJkiQ1zDAnSZLUMMOcJElSwwxzkiRJDTPMSZIkNcwwJ0mS1DDDnCRJUsMMc5IkSQ0zzEmSJDXMMCdJktSwsYa5JCckuSnJ1iTnDuhPkvO7/s1JjpjWvyzJp5J8eOGqliRJWjzGFuaSLAMuAE4E1gHPS7Ju2rATgbXd40zgwmn95wBbRlyqJEnSojXOmbmjgK1VdUtV3QO8F1g/bcx64LLquQbYN8mBAElWAicDlyxk0ZIkSYvJOMPcQcCtfdvburZhx7wDeDVw/6gKlCRJWuzGGeYyoK2GGZPkmcA3qmrTjCdJzkwymWRyx44ds6lTkiRp0RpnmNsGrOrbXgncNuSYpwKnJPkSveXZX0hy+aCTVNXFVTVRVRMrVqyYr9olSZIWhXGGuWuBtUnWJNkLOA3YMG3MBuCF3adajwbuqKrtVXVeVa2sqtXdfv9YVc9f0OolSZIWgeXjOnFV3ZvkbOAKYBnw7qq6MclZXf9FwEbgJGArcDdwxrjqlSRJWoxSNf02taVrYmKiJicnx12GJEnSjJJsqqqJmcb5DRCSJEkNM8xJkiQ1zDAnSZLUMMOcJElSwwxzkiRJDTPMSZIkNcwwJ0mS1DDDnCRJUsMMc5IkSQ0zzEmSJDXMMCdJktQww5wkSVLDDHOSJEkNM8xJkiQ1zDAnSZLUMMOcJElSwwxzkiRJDTPMSZIkNcwwJ0mS1DDDnCRJUsMMc5IkSQ0zzEmSJDXMMCdJktQww5wkSVLDDHOSJEkNM8xJkiQ1zDAnSZLUMMOcJElSwwxzkiRJDTPMSZIkNcwwJ0mS1DDDnCRJUsMMc5IkSQ0zzEmSJDXMMCdJktQww5wkSVLDDHOSJEkNM8xJkiQ1zDAnSZLUMMOcJElSwwxzkiRJDRtrmEtyQpKbkmxNcu6A/iQ5v+vfnOSIrn1Vkn9KsiXJjUnOWfjqJUmSxm9sYS7JMuAC4ERgHfC8JOumDTsRWNs9zgQu7NrvBX6rqp4IHA28fMC+kiRJS944Z+aOArZW1S1VdQ/wXmD9tDHrgcuq5xpg3yQHVtX2qroOoKq+DWwBDlrI4iVJkhaDcYa5g4Bb+7a38R8D2YxjkqwGDgc+MegkSc5MMplkcseOHXMsWZIkaXEZZ5jLgLbanTFJHg68H3hlVd056CRVdXFVTVTVxIoVK2ZdrCRJ0mI0zjC3DVjVt70SuG3YMUkeTC/IvaeqPjDCOiVJkhatcYa5a4G1SdYk2Qs4DdgwbcwG4IXdp1qPBu6oqu1JAvwpsKWq3r6wZUuSJC0ey8d14qq6N8nZwBXAMuDdVXVjkrO6/ouAjcBJwFbgbuCMbvenAi8Abkjy6a7ttVW1cSFfgyRJ0rilavptakvXxMRETU5OjrsMSZKkGSXZVFUTM43zGyAkSZIaZpiTJElqmGFOkiSpYYY5SZKkhhnmJEmSGmaYkyRJaphhTpIkqWGGOUmSpIYZ5iRJkhpmmJMkSWqYYU6SJKlhhjlJkqSGGeYkSZIaZpiTJElqmGFOkiSpYYY5SZKkhhnmJEmSGmaYkyRJaphhTpIkqWGGOUmSpIYZ5iRJkhpmmJMkSWqYYU6SJKlhhjlJkqSGGeYkSZIatnxXnUk2D3GMHVV17DzVI0mSpN2wyzAHLANO2kV/gA3zV44kSZJ2x0xh7r9U1Zd3NSDJy+axHkmSJO2GXd4zV1Ufm96W5IiZxkiSJGlhzOYDEJfMexWSJEmaldmEucx7FZIkSZqV2YS5N8x7FZIkSZqVXYa5JI+d3lZVfzvTGEmSJC2MmWbmNg5xjGHGSJIkaQRm+tUkhyW5cxf9AXbVL0mSpBHaZZirqmULVYgkSZJ2n9/NKkmS1DDDnCRJUsMMc5IkSQ0bOswleVqSM7rnK5KsGV1ZkiRJGsZQYS7J7wGvAc7rmh4MXD7Xkyc5IclNSbYmOXdAf5Kc3/Vv7v9e2Jn2lSRJ2hMMOzP3bOAU4DsAVXUb8Ii5nDjJMuAC4ERgHfC8JOumDTsRWNs9zgQu3I19JUmSlrxhw9w9VVVAASR52Dyc+yhga1XdUlX3AO8F1k8bsx64rHquAfZNcuCQ+0qSJC15w4a59yV5F70w9VLgKuBP5njug4Bb+7a3dW3DjBlmX0mSpCVvpm+AAKCq3prkOHrf9vDjwO9W1ZVzPHcGnWrIMcPs2ztAcia9JVoOPvjg3alPkiRp0ZsxzHX3p11RVU8H5hrg+m0DVvVtrwRuG3LMXkPsC0BVXQxcDDAxMTEw8EmSJLVqxmXWqroPuDvJPvN87muBtUnWJNkLOA3YMG3MBuCF3adajwbuqKrtQ+4rSZK05A21zAp8D7ghyZV0n2gFqKpXzPbEVXVvkrOBK4BlwLur6sYkZ3X9FwEbgZOArcDdwBm72ne2tUiSJLUqvQ+pzjAoOX1Qe1VdOu8VjdDExERNTk6OuwxJkqQZJdlUVRMzjRv2AxCXdsuZT+iabqqq78+lQEmSJM3dUGEuyTHApcCX6H2SdFWS06vqo6MrTZIkSTMZ9p65twHHV9VNAEmeAPwlcOSoCpMkSdLMhv2lwQ+eCnIAVfV5et/PKkmSpDEadmZuMsmfAn/ebf8qsGk0JUmSJGlYw4a5XwdeDryC3j1zHwX+56iKkiRJ0nCGDXPLgT+uqrfDD74VYu+RVSVJkqShDHvP3NXAj/Rt/whw1fyXI0mSpN0xbJh7SFXdNbXRPX/oaEqSJEnSsIYNc99JcsTURpIjge+OpiRJkiQNa9h75l4J/HWS27rtA4HnjqYkSZIkDWvYr/O6NslPAD9O79Osn/PrvCRJksZvqGXWJL9M7765zwDrgb/qX3aVJEnSeAx7z9zvVNW3kzwNeAa972m9cHRlSZIkaRjDhrn7up8nAxdW1YeAvUZTkiRJkoY1bJj7apJ3Ac8BNibZezf2lSRJ0ogMG8ieA1wBnFBVtwP7Ab89sqokSZI0lGE/zXo38IG+7e3A9lEVJUmSpOG4VCpJktQww5wkSVLDDHOSJEkNM8xJkiQ1zDAnSZLUMMOcJElSwwxzkiRJDTPMSZIkNcwwJ0mS1DDDnCRJUsMMc5IkSQ0zzEmSJDXMMCdJktQww5wkSVLDDHOSJEkNM8xJkiQ1zDAnSZLUMMOcJElSwwxzkiRJDTPMSZIkNcwwJ0mS1DDDnCRJUsMMc5IkSQ0bS5hLsl+SK5Pc3P181E7GnZDkpiRbk5zb1/6WJJ9LsjnJB5Psu3DVS5IkLR7jmpk7F7i6qtYCV3fbD5BkGXABcCKwDnheknVd95XAk6vqUODzwHkLUrUkSdIiM64wtx64tHt+KfCsAWOOArZW1S1VdQ/w3m4/quojVXVvN+4aYOWI65UkSVqUxhXmHlNV2wG6nwcMGHMQcGvf9raubboXAX+/sxMlOTPJZJLJHTt2zKFkSZKkxWf5qA6c5CrgsQO6XjfsIQa01bRzvA64F3jPzg5SVRcDFwNMTEzUzsZJkiS1aGRhrqqevrO+JF9PcmBVbU9yIPCNAcO2Aav6tlcCt/Ud43TgmcCxVWVIkyRJe6RxLbNuAE7vnp8OfGjAmGuBtUnWJNkLOK3bjyQnAK8BTqmquxegXkmSpEVpXGHuzcBxSW4Gjuu2SfKjSTYCdB9wOBu4AtgCvK+qbuz2fyfwCODKJJ9OctFCvwBJkqTFYGTLrLtSVf8GHDug/TbgpL7tjcDGAeMeP9ICJUmSGuE3QEiSJDXMMCdJktQww5wkSVLDDHOSJEkNM8xJkiQ1zDAnSZLUMMOcJElSwwxzkiRJDTPMSZIkNcwwJ0mS1DDDnCRJUsMMc5IkSQ0zzEmSJDXMMCdJktQww5wkSVLDDHOSJEkNM8xJkiQ1zDAnSZLUMMOcJElSwwxzkiRJDTPMSZIkNcwwJ0mS1DDDnCRJUsMMc5IkSQ0zzEmSJDXMMCdJktQww5wkSVLDDHOSJEkNM8xJkiQ1zDAnSZLUMMOcJElSwwxzkiRJDTPMSZIkNcwwJ0mS1DDDnCRJUsMMc5IkSQ0zzEmSJDXMMCdJktQww5wkSVLDDHOSJEkNG0uYS7JfkiuT3Nz9fNROxp2Q5KYkW5OcO6D/VUkqyf6jr1qSJGnxGdfM3LnA1VW1Fri6236AJMuAC4ATgXXA85Ks6+tfBRwHfGVBKpYkSVqExhXm1gOXds8vBZ41YMxRwNaquqWq7gHe2+035Y+AVwM1ykIlSZIWs3GFucdU1XaA7ucBA8YcBNzat72tayPJKcBXq+r6URcqSZK0mC0f1YGTXAU8dkDX64Y9xIC2SvLQ7hjHD1nHmcCZAAcffPCQp5YkSWrDyMJcVT19Z31Jvp7kwKranuRA4BsDhm0DVvVtrwRuAx4HrAGuTzLVfl2So6rqawPquBi4GGBiYsIlWUmStKSMa5l1A3B69/x04EMDxlwLrE2yJslewGnAhqq6oaoOqKrVVbWaXug7YlCQkyRJWurGFebeDByX5GZ6n0h9M0CSH02yEaCq7gXOBq4AtgDvq6obx1SvJEnSojSyZdZdqap/A44d0H4bcFLf9kZg4wzHWj3f9UmSJLXCb4CQJElqmGFOkiSpYYY5SZKkhhnmJEmSGmaYkyRJaphhTpIkqWGGOUmSpIYZ5iRJkhpmmJMkSWqYYU6SJKlhhjlJkqSGGeYkSZIaZpiTJElqmGFOkiSpYYY5SZKkhhnmJEmSGmaYkyRJaphhTpIkqWGGOUmSpIYZ5iRJkhpmmJMkSWqYYU6SJKlhhjlJkqSGGeYkSZIaZpiTJElqmGFOkiSpYYY5SZKkhhnmJEmSGmaYkyRJaphhTpIkqWGGOUmSpIYZ5iRJkhqWqhp3DQsmyQ7gy+OuoyH7A98cdxF6AK/J4uR1WXy8JouT12X3HFJVK2YatEeFOe2eJJNVNTHuOvRDXpPFyeuy+HhNFievy2i4zCpJktQww5wkSVLDDHPalYvHXYD+A6/J4uR1WXy8JouT12UEvGdOkiSpYc7MSZIkNcwwt4dLsl+SK5Pc3P181E7GnZDkpiRbk5w7oP9VSSrJ/qOvemmb6zVJ8pYkn0uyOckHk+y7cNUvLUP8uU+S87v+zUmOGHZfzd5sr0uSVUn+KcmWJDcmOWfhq1+a5vJ3petfluRTST68cFUvHYY5nQtcXVVrgau77QdIsgy4ADgRWAc8L8m6vv5VwHHAVxak4qVvrtfkSuDJVXUo8HngvAWpeomZ6c9950Rgbfc4E7hwN/bVLMzlugD3Ar9VVU8EjgZe7nWZuzlekynnAFtGXOqSZZjTeuDS7vmlwLMGjDkK2FpVt1TVPcB7u/2m/BHwasAbMOfHnK5JVX2kqu7txl0DrBxxvUvVTH/u6bYvq55rgH2THDjkvpqdWV+XqtpeVdcBVNW36YWHgxay+CVqLn9XSLISOBm4ZCGLXkoMc3pMVW0H6H4eMGDMQcCtfdvbujaSnAJ8taquH3Whe5A5XZNpXgT8/bxXuGcY5j3e2Zhhr49231yuyw8kWQ0cDnxi3ivc88z1mryD3oTA/aMqcKlbPu4CNHpJrgIeO6DrdcMeYkBbJXlod4zjZ1vbnmpU12TaOV5Hb1npPbtXnTozvse7GDPMvpqduVyXXmfycOD9wCur6s55rG1PNetrkuSZwDeqalOSY+a9sj2EYW4PUFVP31lfkq9PLT90U97fGDBsG7Cqb3slcBvwOGANcH2SqfbrkhxVVV+btxewBI3wmkwd43TgmcCx5e8fmq1dvsczjNlriH01O3O5LiR5ML0g956q+sAI69yTzOWanAqckuQk4CHAI5NcXlXPH2G9S47LrNoAnN49Px340IAx1wJrk6xJshdwGrChqm6oqgOqanVVrab3l/UIg9yczfqaQO9TZcBrgFOq6u4FqHep2ul73GcD8MLuk3pHA3d0S+PD7KvZmfV1Se//Ov8U2FJVb1/Yspe0WV+TqjqvqlZ2/4acBvyjQW73OTOnNwPvS/Jiep9G/WWAJD8KXFJVJ1XVvUnOBq4AlgHvrqobx1bx0jfXa/JOYG/gym7G9JqqOmuhX0TrdvYeJzmr678I2AicBGwF7gbO2NW+Y3gZS85crgvwVOAFwA1JPt21vbaqNi7ka1hq5nhNNA/8BghJkqSGucwqSZLUMMOcJElSwwxzkiRJDTPMSZIkNcwwJ0mS1DDDnCR1kvx+kp3+QufdOM5duzn+viSf7n79zPS+n03y2SSfmWtdkpYmfzWJJM2zJHdV1cPna3z3PaIfrqonz0N5kpYYZ+YkLVlJnp/kk92s17uSLOva70rytiTXJbk6yYqu/c+SnNo9f3M3I7Y5yVu7tkO68Zu7nwd37WuSfDzJtUneOK2G3+7aNyd5w8K+A5L2BIY5SUtSkicCzwWeWlVPAe4DfrXrfhhwXVUdAfwL8HvT9t0PeDbwpKo6FPiDruudwGVd23uA87v2PwYurKqfAr7Wd5zjgbXAUcBTgCOT/Nx8v1ZJezbDnKSl6ljgSODa7qubjgV+rOu7H/ir7vnlwNOm7Xsn8D3gkiS/RO/rhwB+GviL7vmf9+33VOAv+9qnHN89PgVcB/wEvXAnSfPG72aVtFQFuLSqzhti7ANuHu6+a/IoegHwNOBs4Bdm2G/QDcgB/rCq3jVcyZDk2fxwpvAlVTU57L6S9kzOzElaqq4GTk1yAPSWTpMc0vU9CDi1e/4rwMf6d0zycGCf7gvYX0lviRTgX+mFO+gt2U7t93+ntU+5AnhRdzySHDRVz85U1Qer6indwyAnaUbOzElakqrqs0leD3wkyYOA7wMvB74MfAd4UpJNwB307q3r9wjgQ0keQm927b927a8A3p3kt4EdwBld+znAXyQ5B3h/Xw0f6e7d+3gSgLuA5wPfmO/XK2nP5a8mkbTH2d1fHTJq/moSSXPhMqskjd+du/qlwcDfAd9c+LIktcCZOUmSpIY5MydJktQww5wkSVLDDHOSJEkNM8xJkiQ1zDAnSZLUMMOcJElSw/4/ImubWV4N4/gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not os.path.exists(config['RECORD_DIR']):\n",
    "    os.makedirs(config['RECORD_DIR'])\n",
    "if config['VERBOSE'] > 0:\n",
    "    figure, axes, lines = prepare_plots()\n",
    "else:\n",
    "    figure, axes, lines = None, None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = SarsaAgent(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['VERBOSE']= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    " while agent.episode < agent.episode_count:\n",
    "\n",
    "        # Do episode\n",
    "        agent.do_episode(config)\n",
    "\n",
    "        # Update plots\n",
    "        if config['VERBOSE'] > 0:\n",
    "            figure = update_plots(figure, axes, lines, agent.episode, agent.score)\n",
    "\n",
    "        # Save every nth episode\n",
    "        if agent.episode % config['SAVE_EVERY'] == 0 and config['VERBOSE'] > 0:\n",
    "            agent.save_checkpoint(config)\n",
    "            figure.savefig(config['RECORD_DIR'] + 'score.pdf')\n",
    "\n",
    "        # Break when goal of 100-score > 200 is reached\n",
    "        if np.mean(agent.score_100) >= 200.0:\n",
    "            if config['VERBOSE'] > 0:\n",
    "                agent.save_checkpoint(config)\n",
    "                figure.savefig(config['RECORD_DIR'] + 'score.pdf')\n",
    "            logger.info('Goal reached!')\n",
    "            break\n",
    "\n",
    "    # Close\n",
    "agent.env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
