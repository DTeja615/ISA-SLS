{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "from collections import deque\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "from bottleneck import move_mean\n",
    "from gym import logger\n",
    "from gym.wrappers import Monitor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent:\n",
    "    \"\"\"\n",
    "    Base class for Reinforcement Learning agent\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "\n",
    "        # Running configuration\n",
    "        self.run = 0\n",
    "        self.step = 0\n",
    "        self.episode = 0\n",
    "        self.episode_count = config['EPISODES']\n",
    "\n",
    "        # Env\n",
    "        self.env_id = config['ENV_ID']\n",
    "        self.env_seed = config['ENV_SEED']\n",
    "        if config['VERBOSE'] > 0:\n",
    "            self.env = Monitor(gym.make(self.env_id), directory=config['RECORD_DIR'] + f'run_{self.run}',\n",
    "                               video_callable=lambda episode_id: episode_id % config['SAVE_EVERY'] == 0,\n",
    "                               force=True,\n",
    "                               uid=config['AGENT'])\n",
    "        else:\n",
    "            self.env = gym.make(self.env_id)\n",
    "        self.env.seed(self.env_seed)\n",
    "\n",
    "        # generating a random number\n",
    "        self.prng = np.random.RandomState(self.env_seed)\n",
    "\n",
    "        self.score = deque(maxlen=self.episode_count)\n",
    "        self.score_100 = deque(maxlen=100)  # last 100 mean\n",
    "\n",
    "    def act(self, *args):\n",
    "       \n",
    "        #Performing a random action\n",
    "        \n",
    "        return self.prng.randint(self.env.action_space.n)\n",
    "\n",
    "    def do_episode(self, config):\n",
    "\n",
    "        # Initial values\n",
    "        done = False\n",
    "        score_e = 0\n",
    "        step_e = 0\n",
    "\n",
    "        # Reset environment\n",
    "        self.env.reset()\n",
    "\n",
    "        while not done:\n",
    "\n",
    "            # display on screen\n",
    "            if config['VERBOSE'] > 1:\n",
    "                self.env.render()\n",
    "\n",
    "            # Action\n",
    "            action = self.act()\n",
    "            _, reward, done, _ = self.env.step(action)\n",
    "\n",
    "            # Increase the score and steps\n",
    "            score_e += reward\n",
    "            step_e += 1\n",
    "            self.step += 1\n",
    "\n",
    "        # Appending the score\n",
    "        self.score.append(score_e)\n",
    "        self.score_100.append(score_e)\n",
    "        mean_score = np.mean(self.score_100)\n",
    "\n",
    "        # Increasing the episodes\n",
    "        self.episode += 1\n",
    "\n",
    "        if config['VERBOSE'] > 0:\n",
    "            logger.info(f'[Episode {self.episode}] - score: {score_e:.2f}, steps: {step_e}, '\n",
    "                        f'100-score: {mean_score:.2f}.')\n",
    "\n",
    "    def get_best_score(self):\n",
    "\n",
    "        # Best score is the highest 100-episode score that is reached when score < 200,\n",
    "        # or the episode when score >= 200\n",
    "        score_100 = move_mean(self.score, window=(100 if len(self.score) > 99 else len(self.score)), min_count=1)\n",
    "\n",
    "        # Get max\n",
    "        ep_max = np.argmax(score_100)\n",
    "        score_max = score_100[ep_max]\n",
    "\n",
    "        if score_max >= 200.0:\n",
    "            ep_max = np.argmax(score_100 >= 200.0)\n",
    "            score_max = 200.0\n",
    "\n",
    "        return int(ep_max), float(score_max)\n",
    "\n",
    "    def save_checkpoint(self, config):\n",
    "\n",
    "        #Configuring Parameters\n",
    "        dummy_env = self.env\n",
    "        self.env = None\n",
    "\n",
    "        # Save checkpoint\n",
    "        with open(config['RECORD_DIR'] + 'checkpoint.pickle', 'wb') as p_file:\n",
    "            pickle.dump(self, p_file)\n",
    "\n",
    "        # Save config\n",
    "        with open(config['RECORD_DIR'] + 'config.json', 'w') as c_file:\n",
    "            json.dump(config, c_file, sort_keys=True, indent=4)\n",
    "\n",
    "        self.env = dummy_env\n",
    "\n",
    "        \n",
    "class SarsaAgent(RandomAgent):\n",
    "    \"\"\"\n",
    "    Agent that makes use of Sarsa (on-policy TD control).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "\n",
    "        # Initialize base class\n",
    "        super().__init__(config)\n",
    "\n",
    "        # State\n",
    "        self.state_bounds = config['STATE_BOUNDS']\n",
    "        self.state_bins = tuple(config['STATE_BINS'])\n",
    "\n",
    "        # Float conversion\n",
    "        for i, lr in enumerate(config['LEARNING_RATE']):\n",
    "            if type(lr) is str:\n",
    "                config['LEARNING_RATE'][i] = float(lr)\n",
    "        for i, eps in enumerate(config['E_GREEDY']):\n",
    "            if type(eps) is str:\n",
    "                config['E_GREEDY'][i] = float(eps)\n",
    "\n",
    "        # Learning parameters\n",
    "        # First linear decay, then exponential decay\n",
    "        self.alpha_start, self.alpha_end, self.alpha_steps, self.alpha_decay = config['LEARNING_RATE']\n",
    "        self.epsilon_start, self.epsilon_end, self.epsilon_steps, self.epsilon_decay = config['E_GREEDY']\n",
    "        self.alpha, self.epsilon = self.alpha_start, self.epsilon_start\n",
    "        self.gamma = float(config['DISCOUNT_RATE'])\n",
    "\n",
    "        # Q-table\n",
    "        self.q_table = self.prng.uniform(low=-1.0, high=1.0, size=self.state_bins + (self.env.action_space.n,))\n",
    "\n",
    "    def act(self, state):\n",
    "\n",
    "        if self.prng.random_sample() < self.epsilon:\n",
    "            return self.prng.randint(self.env.action_space.n)\n",
    "        else:\n",
    "            return np.argmax(self.q_table[state])\n",
    "\n",
    "    def discretize_state(self, state):\n",
    "\n",
    "        # First calculate the ratios, then convert to bin indices\n",
    "        ratios = [(state[i] + abs(self.state_bounds[i][0])) / (self.state_bounds[i][1] - self.state_bounds[i][0]) for i\n",
    "                  in range(len(state))]\n",
    "        state_d = [int(round((self.state_bins[i] - 1) * ratios[i])) for i in range(len(state))]\n",
    "        state_d = [min(self.state_bins[i] - 1, max(0, state_d[i])) for i in range(len(state))]\n",
    "\n",
    "        return tuple(state_d)\n",
    "\n",
    "    def learn(self, done, state, action, reward, state_, action_):\n",
    "\n",
    "        # Get current Q(s, a)\n",
    "        q_value = self.q_table[state][action]\n",
    "\n",
    "        # Check if next state is terminal, get next Q(s', a')\n",
    "        if not done:\n",
    "            q_value_ = reward + self.gamma * self.q_table[state_][action_]\n",
    "        else:\n",
    "            q_value_ = reward\n",
    "\n",
    "        # Update current Q(s, a)\n",
    "        self.q_table[state][action] += self.alpha * (q_value_ - q_value)\n",
    "\n",
    "    def do_episode(self, config):\n",
    "\n",
    "        # Initial values\n",
    "        done = False\n",
    "        score_e = 0\n",
    "        step_e = 0\n",
    "\n",
    "        # Get epsilon for initial state\n",
    "        self.update_epsilon_step()\n",
    "\n",
    "        # Episodic decay (only after linear decay)\n",
    "        self.update_alpha_episode()\n",
    "        self.update_epsilon_episode()\n",
    "\n",
    "        # Get current state s, act based on s\n",
    "        state = self.discretize_state(self.env.reset())\n",
    "        action = self.act(state)\n",
    "\n",
    "        while not done:\n",
    "\n",
    "            # Show on screen\n",
    "            if config['VERBOSE'] > 1:\n",
    "                self.env.render()\n",
    "\n",
    "            # Update for other steps\n",
    "            self.update_alpha_step()\n",
    "            self.update_epsilon_step()\n",
    "\n",
    "            # Get next state s' and reward, act based on s'\n",
    "            state_, reward, done, _ = self.env.step(action)\n",
    "            state_ = self.discretize_state(state_)\n",
    "            action_ = self.act(state_)\n",
    "\n",
    "            # Learn\n",
    "            self.learn(done, state, action, reward, state_, action_)\n",
    "\n",
    "            # Set next state and action to current\n",
    "            state = state_\n",
    "            action = action_\n",
    "\n",
    "            # Increasing score and steps\n",
    "            score_e += reward\n",
    "            step_e += 1\n",
    "            self.step += 1\n",
    "\n",
    "        # Appending score\n",
    "        self.score.append(score_e)\n",
    "        self.score_100.append(score_e)\n",
    "        mean_score = np.mean(self.score_100)\n",
    "\n",
    "        # Increasing episode\n",
    "        self.episode += 1\n",
    "\n",
    "        if config['VERBOSE'] > 0:\n",
    "            logger.info(f'[Episode {self.episode}] - score: {score_e:.2f}, steps: {step_e}, e: {self.epsilon:.4f}, '\n",
    "                        f'a: {self.alpha:.4f}, 100-score: {mean_score:.2f}.')\n",
    "\n",
    "    def update_alpha_step(self):\n",
    "\n",
    "        # Linear decay\n",
    "        if self.step <= self.alpha_steps and self.alpha_steps > 0:\n",
    "            self.alpha = self.alpha_start - self.step * (self.alpha_start - self.alpha_end) / self.alpha_steps\n",
    "\n",
    "    def update_epsilon_step(self):\n",
    "\n",
    "        # Linear decay\n",
    "        if self.step <= self.epsilon_steps and self.epsilon_steps > 0:\n",
    "            self.epsilon = self.epsilon_start - self.step * (self.epsilon_start - self.epsilon_end) / self.epsilon_steps\n",
    "\n",
    "    def update_alpha_episode(self):\n",
    "\n",
    "        # Exponential decay\n",
    "        if self.step > self.alpha_steps:\n",
    "            self.alpha *= self.alpha_decay\n",
    "\n",
    "    def update_epsilon_episode(self):\n",
    "\n",
    "        # Exponential decay\n",
    "        if self.step > self.epsilon_steps:\n",
    "            self.epsilon *= self.epsilon_decay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "from bottleneck import move_mean\n",
    "from gym.wrappers import Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_plots():\n",
    "\n",
    "    # Interactive, style\n",
    "    plt.ion()\n",
    "\n",
    "    # Get figure and subplots\n",
    "    figure = plt.figure(figsize=(10, 5))\n",
    "    axes = [figure.add_subplot(111)]  # 121), figure.add_subplot(122)]\n",
    "\n",
    "    # Configure subplots\n",
    "    axes[0].set_xlabel('episode [-]')\n",
    "    axes[0].set_ylabel('score [-]')\n",
    "    axes[0].set_title('Score moving average', fontstyle='italic')\n",
    "    # axes[1].set_xlabel('episode')\n",
    "    # axes[1].set_ylabel('score')\n",
    "    # axes[1].set_title('Score moving average over episodes', fontstyle='italic')\n",
    "\n",
    "    # Get lines\n",
    "    lines = [axes[0].plot([0])[0]]\n",
    "\n",
    "    return figure, axes, lines\n",
    "\n",
    "\n",
    "def update_plots(figure, axes, lines, episode, score):\n",
    "\n",
    "    # Moving average\n",
    "    score_ma = move_mean(score, window=(100 if len(score) > 99 else len(score)), min_count=1)\n",
    "\n",
    "    # Update plot\n",
    "    lines[0].set_data(range(1, episode + 1), score_ma)\n",
    "\n",
    "    # Rescale axes\n",
    "    for ax in axes:\n",
    "        ax.relim()\n",
    "        ax.autoscale_view()\n",
    "\n",
    "    # Update figure\n",
    "    figure.tight_layout()\n",
    "    figure.canvas.draw()\n",
    "    figure.canvas.flush_events()\n",
    "\n",
    "    return figure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import yaml\n",
    "from gym import logger\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = 'config/config_sarsa.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "with open(config, 'r') as config_file:\n",
    "    config = yaml.load(config_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ENV_ID': 'LunarLander-v2',\n",
       " 'ENV_SEED': 0,\n",
       " 'AGENT': 'sarsa',\n",
       " 'RECORD_DIR': 'record/sarsa/',\n",
       " 'CHECKPOINT_DIR': '',\n",
       " 'EPISODES': 8000,\n",
       " 'SAVE_EVERY': 100,\n",
       " 'STATE_BINS': [5, 5, 5, 5, 5, 5, 2, 2],\n",
       " 'STATE_BOUNDS': [[-1.0, 1.0],\n",
       "  [-1.0, 1.0],\n",
       "  [-1.0, 1.0],\n",
       "  [-1.0, 1.0],\n",
       "  [-1.0, 1.0],\n",
       "  [-1.0, 1.0],\n",
       "  [-1.0, 1.0],\n",
       "  [-1.0, 1.0]],\n",
       " 'VERBOSE': 1,\n",
       " 'CONTINUE': False,\n",
       " 'E_GREEDY': [1.0, 0.05, '1e5', 0.99],\n",
       " 'LEARNING_RATE': [0.2, 0.2, 0, 1],\n",
       " 'DISCOUNT_RATE': 0.97}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not os.path.exists(config['RECORD_DIR']):\n",
    "    os.makedirs(config['RECORD_DIR'])\n",
    "if config['VERBOSE'] > 0:\n",
    "    figure, axes, lines = prepare_plots()\n",
    "else:\n",
    "    figure, axes, lines = None, None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = SarsaAgent(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['VERBOSE']= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " while agent.episode < agent.episode_count:\n",
    "\n",
    "        # Do episode\n",
    "        agent.do_episode(config)\n",
    "\n",
    "        # Update plots\n",
    "        if config['VERBOSE'] > 0:\n",
    "            figure = update_plots(figure, axes, lines, agent.episode, agent.score)\n",
    "\n",
    "        # Save every nth episode\n",
    "        if agent.episode % config['SAVE_EVERY'] == 0 and config['VERBOSE'] > 0:\n",
    "            agent.save_checkpoint(config)\n",
    "            figure.savefig(config['RECORD_DIR'] + 'score.pdf')\n",
    "\n",
    "        # Break when goal of 100-score > 200 is reached\n",
    "        if np.mean(agent.score_100) >= 200.0:\n",
    "            if config['VERBOSE'] > 0:\n",
    "                agent.save_checkpoint(config)\n",
    "                figure.savefig(config['RECORD_DIR'] + 'score.pdf')\n",
    "            logger.info('Goal reached!')\n",
    "            break\n",
    "\n",
    "    # Close\n",
    "agent.env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
